## DEPRECATED!! USING LANGGRAPH AGENTIC NOW

import os
import time
from google import genai
from app.models.request import AIRequest, UriRequest
from app.models.conversation import Message
from app.models.video import GeminiUriProvider
from app.utils.time_util import convert_seconds_to_minutes, get_youtube_video_duration, get_file_video_duration
from app.utils.conversation_util import convert_conversation_to_google_format, convert_conversation_to_langchain_format
from app.utils.model_config_util import generate_model_config_for_gemini
from langchain_google_genai import ChatGoogleGenerativeAI

class GeminiService:

    @staticmethod
    def upload_video_to_gemini(request:UriRequest):
        file_path = request.video.path

        # Check file existence
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")

        # Check file size
        file_size = os.path.getsize(file_path)
        if file_size == 0:
            raise ValueError(f"File is empty: {file_path}")

        client = genai.Client(api_key=request.api_key if request.api_key is not None else os.environ.get("GEMINI_API_KEY"))
        try:
            myfile = client.files.upload(file=request.video.path)
        except Exception as e:
            return {"error": f"Error uploading file to Gemini's Side: {str(e)}"}

        while myfile.state.name == "PROCESSING":
            time.sleep(5)  # Wait 5 seconds between checks
            myfile = client.files.get(name=myfile.name)
        
        request.video.uri = myfile.uri

        if request.video.uri_data is None:
            request.video.uri_data = GeminiUriProvider(uri_file_name=myfile.name, uri_state=myfile.state.name, uri_mime_type=myfile.mime_type)

        request.video.duration = convert_seconds_to_minutes(float(myfile.video_metadata['videoDuration'].replace('s', '')))

        return request.model_dump()

    @staticmethod
    def process(request: AIRequest):
        """Process AI request using Gemini while maintaining history"""

        api_key = request.api_key if request.api_key else os.environ.get("GEMINI_API_KEY")
        client = genai.Client(api_key=api_key)

        # Convert conversation history to Gemini format
        parts = convert_conversation_to_google_format(request)
        generate_content_config = generate_model_config_for_gemini(request)

        # Call Gemini AI
        try:
            result = client.models.generate_content(
                model=request.model_name,
                contents=parts,
                config=generate_content_config,
            )

            if not result or not result.candidates:
                raise ValueError("No response generated by Gemini.")

            ai_response = result.text # Extract AI response

            new_message = Message(role="model", content=ai_response)

            updated_history = request.conversation_history.messages + [new_message]

            return {"conversation_history": [msg.model_dump() for msg in updated_history]}

        except Exception as e:
            return {"error": str(e)}

    @staticmethod
    def process_langchain(request: AIRequest):
        """Process AI request using Gemini with Langchain"""

        api_key = request.api_key if request.api_key else os.environ.get("GEMINI_API_KEY")
        model = ChatGoogleGenerativeAI(model=request.model_name, temperature=0.6, max_output_tokens=8192, api_key=api_key)

        conversation_list = convert_conversation_to_langchain_format(request)

        result = model.invoke(conversation_list)

        new_message = Message(role="model", content=result.content)

        updated_history = request.conversation_history.messages + [new_message]

        return {"conversation_history": [msg.model_dump() for msg in updated_history]}
